{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polars - Getting to know the Syntax\n",
    "\n",
    "Polars is a lightning fast DataFrame library. The [key features](https://docs.pola.rs/) of polars are:\n",
    "\n",
    "**Fast and Accessible**: Written from scratch in Rust, designed close to the machine and without external dependencies. It also has python and R bindings!\n",
    "\n",
    "**I/O**: First class support for all common data storage layers: local, cloud storage & databases.\n",
    "\n",
    "**Handle Datasets** larger than RAM\n",
    "\n",
    "**Intuitive API**: Write your queries the way they were intended. Polars, internally, will determine the most efficient way to execute using its query optimizer.\n",
    "Out of Core: The streaming API allows you to process your results without requiring all your data to be in memory at the same time\n",
    "\n",
    "**Parallel**: Utilises the power of your machine by dividing the workload among the available CPU cores without any additional configuration.\n",
    "\n",
    "\n",
    "The philosophy of Polars is to provide a dataframe library that utilises available cores, has an intuitive api and is performance - hence adheres to a strict schema (data-types should be known before running the query).\n",
    "\n",
    "\n",
    "In its domains specific language that is designed to be human readable while performing common data manipulation processes, polars describes its operations with [Contexts](https://docs.pola.rs/user-guide/concepts/contexts/) and [Expressions](https://docs.pola.rs/user-guide/concepts/expressions/). Contexts refers to the context in which an expression needs to be evaluated - i.e Filtering, Selecting and Groupby aggregations.  \n",
    "\n",
    "\n",
    "`select` : select columns\n",
    "\n",
    "`filter` : filter rows\n",
    "\n",
    "`with_columns` : create / do something with columns\n",
    "\n",
    "`group_by` : group by a factor and follow with\n",
    "\n",
    "`agg` : aggregation\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from datetime import datetime\n",
    "\n",
    "# Data Frames and Series are supported by polars\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"integer\": [1, 2, 3,4],\n",
    "        \"date\": [\n",
    "            datetime(2025, 1, 1),\n",
    "            datetime(2025, 1, 2),\n",
    "            datetime(2025, 1, 3),\n",
    "            datetime(2025, 1, 3),\n",
    "        ],\n",
    "        \"float\": [4.0, 5.0, 6.0,12],\n",
    "        \"string\": [\"a\", \"b\", \"c\",\"b\"],\n",
    "    }\n",
    ")\n",
    "# Seriers types need to be the same\n",
    "sr = pl.Series([1,2,3,4,500])\n",
    "# can specify the data types for better performance\n",
    "\n",
    "sr = pl.Series([1,2,3,4,500],dtype=pl.Int64)\n",
    "\n",
    "\n",
    "df2 = pl.DataFrame(\n",
    "    {\n",
    "        \"x\": range(8),\n",
    "        \"y\": [\"A\", \"A\", \"A\", \"B\", \"B\", \"C\", \"X\", \"X\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>integer</th><th>date</th><th>float</th><th>string</th></tr><tr><td>i64</td><td>datetime[μs]</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>2025-01-01 00:00:00</td><td>4.0</td><td>&quot;a&quot;</td></tr><tr><td>2</td><td>2025-01-02 00:00:00</td><td>5.0</td><td>&quot;b&quot;</td></tr><tr><td>3</td><td>2025-01-03 00:00:00</td><td>6.0</td><td>&quot;c&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 4)\n",
       "┌─────────┬─────────────────────┬───────┬────────┐\n",
       "│ integer ┆ date                ┆ float ┆ string │\n",
       "│ ---     ┆ ---                 ┆ ---   ┆ ---    │\n",
       "│ i64     ┆ datetime[μs]        ┆ f64   ┆ str    │\n",
       "╞═════════╪═════════════════════╪═══════╪════════╡\n",
       "│ 1       ┆ 2025-01-01 00:00:00 ┆ 4.0   ┆ a      │\n",
       "│ 2       ┆ 2025-01-02 00:00:00 ┆ 5.0   ┆ b      │\n",
       "│ 3       ┆ 2025-01-03 00:00:00 ┆ 6.0   ┆ c      │\n",
       "└─────────┴─────────────────────┴───────┴────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To inspect the data you can use head(),tail(),print()\n",
    "# sample() to select random rows, and describe() for sumamry statistics\n",
    "df.describe()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expressions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polars has a powerful concept called expressions that is central to its very fast performance.\n",
    "\n",
    "Expressions are at the core of many data science operations. Essentially they represent data transformations within the above contexts (selecting, filtering, aggregating). Common expressions are taking a sample of rows from a column, multiplying values in a column, extracting a column of years from dates ... and so on.\n",
    "\n",
    "The important thing about expressions in polar, and why its central to its very fast performance, is Polars perfoms:\n",
    "\n",
    "1. automatic query **optimization** on each expression\n",
    "\n",
    "2. automatic **parallelization** of expressions on many columns\n",
    "\n",
    "For more info and examples on [expressions](https://docs.pola.rs/user-guide/expressions/).\n",
    "\n",
    "**All expressions are run in parallel, meaning that separate Polars expressions are embarrassingly parallel. Note that within an expression there may be more parallelization going on.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning the Syntax\n",
    "Basic examples of expressions and contexts are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>string</th><th>sum</th><th>earliest</th><th>float</th></tr><tr><td>str</td><td>i64</td><td>datetime[μs]</td><td>list[f64]</td></tr></thead><tbody><tr><td>&quot;a&quot;</td><td>1</td><td>2025-01-01 00:00:00</td><td>[4.0]</td></tr><tr><td>&quot;b&quot;</td><td>6</td><td>2025-01-02 00:00:00</td><td>[2.5, 3.0]</td></tr><tr><td>&quot;c&quot;</td><td>3</td><td>2025-01-03 00:00:00</td><td>[2.0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 4)\n",
       "┌────────┬─────┬─────────────────────┬────────────┐\n",
       "│ string ┆ sum ┆ earliest            ┆ float      │\n",
       "│ ---    ┆ --- ┆ ---                 ┆ ---        │\n",
       "│ str    ┆ i64 ┆ datetime[μs]        ┆ list[f64]  │\n",
       "╞════════╪═════╪═════════════════════╪════════════╡\n",
       "│ a      ┆ 1   ┆ 2025-01-01 00:00:00 ┆ [4.0]      │\n",
       "│ b      ┆ 6   ┆ 2025-01-02 00:00:00 ┆ [2.5, 3.0] │\n",
       "│ c      ┆ 3   ┆ 2025-01-03 00:00:00 ┆ [2.0]      │\n",
       "└────────┴─────┴─────────────────────┴────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.select(pl.col(\"float\")) # selecting a column\n",
    "\n",
    "df.select(pl.col(\"date\",\"string\")) # selecting multiple columns \n",
    "#(use \"*\" or pl.all() for all columns)\n",
    "\n",
    "df.filter(pl.col(\"integer\") >= 2)  #filtering rows\n",
    "\n",
    "df.filter((pl.col(\"integer\") >=2) & \n",
    "          (pl.col(\"float\") == 5.0)) #filtering rows with multiple conditions (| = or & = and)\n",
    "\n",
    "df.with_columns((pl.col(\"integer\") + 3).alias(\"new_column\")) # creating column and naming it\n",
    "\n",
    "df.group_by(\"string\").agg(pl.col(\"integer\").sum().alias(\"sum\"),\n",
    "                          pl.col(\"date\").sort().first().alias(\"earliest\"), \n",
    "                          pl.col(\"float\") / pl.col(\"integer\")) \n",
    "                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to use [Select](https://docs.pola.rs/user-guide/expressions/column-selections/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>product</th><th>string</th></tr><tr><td>f64</td><td>str</td></tr></thead><tbody><tr><td>4.0</td><td>&quot;a&quot;</td></tr><tr><td>10.0</td><td>&quot;b&quot;</td></tr><tr><td>18.0</td><td>&quot;c&quot;</td></tr><tr><td>48.0</td><td>&quot;b&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 2)\n",
       "┌─────────┬────────┐\n",
       "│ product ┆ string │\n",
       "│ ---     ┆ ---    │\n",
       "│ f64     ┆ str    │\n",
       "╞═════════╪════════╡\n",
       "│ 4.0     ┆ a      │\n",
       "│ 10.0    ┆ b      │\n",
       "│ 18.0    ┆ c      │\n",
       "│ 48.0    ┆ b      │\n",
       "└─────────┴────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can combine expressions for compactness\n",
    "# Can use regular expressions and helper functions to select columns in different ways\n",
    "import polars.selectors as cs\n",
    "df3 = df.with_columns((pl.col(\"float\") * pl.col(\"integer\"))\n",
    "                .alias(\"product\")).select(pl.all().exclude(\"integer\")).select(cs.contains(\"uct\"),cs.string())\n",
    "                \n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other info:\n",
    "\n",
    "\n",
    "Polars supports traditional [Data Transformation](https://docs.pola.rs/user-guide/transformations/) such as join, Concatenation, pivot and unpivot. \n",
    "\n",
    "Polars provides many [functions for expressions](https://docs.pola.rs/api/python/stable/reference/expressions/functions.html/). Check out the [API documentation](https://docs.pola.rs/api/python/stable/reference/index.html) for more information "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data types\n",
    "\n",
    "Under the hood polars use Arrow data types and memory arrays and offer support for String, Numberic, Nested, Temporay and other types. Most data types are specified by the arrow [syntax](https://docs.pola.rs/user-guide/concepts/data-types/overview/) with the exception of String, Categorical and Object types.\n",
    "\n",
    "Categorical data represents string data where the values in the column have a finite set of values (yet for performance implementation different to strings). Polars supports both **Enum** data type, where categories are known up front, and the more flexible **Categorical** data type where values are not known beforehand. Conversion between them is trivial. Relying on polars inferring the categories with Categorical types comes at a performance cost (as the encoding is a dictionary like object). See [Categorical](https://docs.pola.rs/user-guide/concepts/data-types/categoricals/#categorical-data-type) page for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Enum where categories are known\n",
    "cat_types = pl.Enum([\"polar\",\"panda\",\"teddy\"])\n",
    "animals = pl.Series([\"polar\",\"polar\",\"teddy\",\"panda\"],dtype= cat_types)\n",
    "# Use Categprical otherwise\n",
    "fictional_animals = pl.Series([\"poobear\",\"minimouse\",\"teddy\",\"poobear\"],dtype= pl.Categorical)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy / Eager API\n",
    "\n",
    "Polars supports two modes of operation: lazy and eager. In the eager API the query is executed immediately while in the lazy API the query is only evaluated once it is 'needed'. Deferring the execution to the last minute can have significant performance advantages.\n",
    "\n",
    "Before we explore the two run this code to fetch the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch iris dataset and save as csv in local path\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "iris = fetch_ucirepo(id=53) \n",
    "X = iris.data.features \n",
    "y = iris.data.targets \n",
    "iris_df = pd.concat([X, y], axis=1)\n",
    "iris_df.rename(columns={'class': 'species'}, inplace=True)\n",
    "iris_df.to_csv(\"iris_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we use the eager API we\n",
    "1. Read the iris dataset.\n",
    "2. Filter the dataset based on sepal length\n",
    "3. Calculate the mean of the sepal width per species\n",
    "\n",
    "Every step is executed immediately returning the intermediate results. This can be very wasteful as we might do work or load extra data that is not being used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(\"iris_data.csv\")\n",
    "df_small = df.filter(pl.col(\"sepal length\") > 5)\n",
    "df_agg = df_small.group_by(\"species\").agg(pl.col(\"sepal width\").mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we instead used the lazy API and waited on execution until all the steps are defined then the query planner could perform various optimizations. In this case:\n",
    "\n",
    "1. Predicate pushdown: Apply filters as early as possible while reading the dataset, thus only reading rows with sepal length greater than 5.\n",
    "\n",
    "2. Projection pushdown: Select only the columns that are needed while reading the dataset, thus removing the need to load additional columns (e.g. petal length & petal width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = (\n",
    "    pl.scan_csv(\"iris_data.csv\") #doesnt read it all before other operation is performed\n",
    "        .filter(pl.col(\"sepal length\") > 5)\n",
    "        .group_by(\"species\").agg(pl.col(\"sepal width\").mean())\n",
    ")\n",
    "\n",
    "q # a lazyframe\n",
    "\n",
    "df_agg = q.collect() # inform polars that you want to execute the query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One additional benefit of the lazy API is that it allows queries to be executed in a streaming manner. Instead of processing the data all-at-once Polars can execute the query in batches allowing you to process datasets that are larger-than-memory. To tell Polars we want to execute a query in streaming mode we pass the streaming=True argument to collect.\n",
    "\n",
    "When to use Lazy versus Eager:\n",
    "\n",
    "In general the lazy API should be preferred unless you are either interested in the intermediate results or are doing exploratory work and don't know yet what your query is going to look like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Typical pipeline Demo \n",
    "\n",
    "Given your new knowledge of polars, here is an example on how to integrate into the usual pipeline consisting of:\n",
    "\n",
    "1. Data ingestion and manipulation.\n",
    "\n",
    "2. Data visualization\n",
    "\n",
    "3. Model Preperation - Training and Testing\n",
    "\n",
    "4. Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Do you aggregating and manipulation to clean data\n",
    "# keep \"as lazy\" as possible\n",
    "q = (\n",
    "    pl.scan_csv(\"iris_data.csv\") # data manipulation stuff - trivial example\n",
    "        .filter(pl.col(\"sepal length\") > 2)\n",
    ")\n",
    "\n",
    "iris_df = q.collect() #trigger computation on and store the polars dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ecosystem\n",
    "\n",
    "On [this](https://docs.pola.rs/user-guide/ecosystem/#key-features) page you can find a non-exhaustive list of libraries and tools that support Polars. As the data ecosystem is evolving fast, more libraries will likely support Polars in the future. One of the main drivers is that Polars makes adheres its memory layout to the Apache Arrow spec.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polars dataframs has kMachine learning \n",
    "\n",
    "# Example preprocessing with Polars: Adding a new feature\n",
    "iris_df = df.with_columns(\n",
    "    (df['sepal length'] * df['sepal width']).alias('sepal area')\n",
    ")\n",
    "\n",
    "# Separate features and target for scikit-learn\n",
    "X = iris_df.select(['sepal length', 'sepal width', 'petal length', 'petal width', 'sepal area'])\n",
    "y = iris_df.select('species').to_series()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (150, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sepal length</th><th>sepal width</th><th>petal length</th><th>petal width</th><th>species</th><th>sepal area</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>5.1</td><td>3.5</td><td>1.4</td><td>0.2</td><td>&quot;Iris-setosa&quot;</td><td>17.85</td></tr><tr><td>4.9</td><td>3.0</td><td>1.4</td><td>0.2</td><td>&quot;Iris-setosa&quot;</td><td>14.7</td></tr><tr><td>4.7</td><td>3.2</td><td>1.3</td><td>0.2</td><td>&quot;Iris-setosa&quot;</td><td>15.04</td></tr><tr><td>4.6</td><td>3.1</td><td>1.5</td><td>0.2</td><td>&quot;Iris-setosa&quot;</td><td>14.26</td></tr><tr><td>5.0</td><td>3.6</td><td>1.4</td><td>0.2</td><td>&quot;Iris-setosa&quot;</td><td>18.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>6.7</td><td>3.0</td><td>5.2</td><td>2.3</td><td>&quot;Iris-virginica&quot;</td><td>20.1</td></tr><tr><td>6.3</td><td>2.5</td><td>5.0</td><td>1.9</td><td>&quot;Iris-virginica&quot;</td><td>15.75</td></tr><tr><td>6.5</td><td>3.0</td><td>5.2</td><td>2.0</td><td>&quot;Iris-virginica&quot;</td><td>19.5</td></tr><tr><td>6.2</td><td>3.4</td><td>5.4</td><td>2.3</td><td>&quot;Iris-virginica&quot;</td><td>21.08</td></tr><tr><td>5.9</td><td>3.0</td><td>5.1</td><td>1.8</td><td>&quot;Iris-virginica&quot;</td><td>17.7</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (150, 6)\n",
       "┌──────────────┬─────────────┬──────────────┬─────────────┬────────────────┬────────────┐\n",
       "│ sepal length ┆ sepal width ┆ petal length ┆ petal width ┆ species        ┆ sepal area │\n",
       "│ ---          ┆ ---         ┆ ---          ┆ ---         ┆ ---            ┆ ---        │\n",
       "│ f64          ┆ f64         ┆ f64          ┆ f64         ┆ str            ┆ f64        │\n",
       "╞══════════════╪═════════════╪══════════════╪═════════════╪════════════════╪════════════╡\n",
       "│ 5.1          ┆ 3.5         ┆ 1.4          ┆ 0.2         ┆ Iris-setosa    ┆ 17.85      │\n",
       "│ 4.9          ┆ 3.0         ┆ 1.4          ┆ 0.2         ┆ Iris-setosa    ┆ 14.7       │\n",
       "│ 4.7          ┆ 3.2         ┆ 1.3          ┆ 0.2         ┆ Iris-setosa    ┆ 15.04      │\n",
       "│ 4.6          ┆ 3.1         ┆ 1.5          ┆ 0.2         ┆ Iris-setosa    ┆ 14.26      │\n",
       "│ 5.0          ┆ 3.6         ┆ 1.4          ┆ 0.2         ┆ Iris-setosa    ┆ 18.0       │\n",
       "│ …            ┆ …           ┆ …            ┆ …           ┆ …              ┆ …          │\n",
       "│ 6.7          ┆ 3.0         ┆ 5.2          ┆ 2.3         ┆ Iris-virginica ┆ 20.1       │\n",
       "│ 6.3          ┆ 2.5         ┆ 5.0          ┆ 1.9         ┆ Iris-virginica ┆ 15.75      │\n",
       "│ 6.5          ┆ 3.0         ┆ 5.2          ┆ 2.0         ┆ Iris-virginica ┆ 19.5       │\n",
       "│ 6.2          ┆ 3.4         ┆ 5.4          ┆ 2.3         ┆ Iris-virginica ┆ 21.08      │\n",
       "│ 5.9          ┆ 3.0         ┆ 5.1          ┆ 1.8         ┆ Iris-virginica ┆ 17.7       │\n",
       "└──────────────┴─────────────┴──────────────┴─────────────┴────────────────┴────────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Possible demo in  either using scikit-learn or an easier ML package to do classification\n",
    "# Tom.M\n",
    "iris_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
