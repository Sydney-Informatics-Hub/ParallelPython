{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background - What is Parallel Python\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel computing is when many different tasks are carried out simultaneously. It does this by creating independent processes ship data, program files and libraries to an isloated ecosystem where computation is performed. There are three main models:\n",
    "\n",
    "- **Embarrassingly parallel:** the code does not need to synchronize/communicate with other instances, and you can run multiple instances of the code separately, and combine the results later. If you can do this, great! (array jobs, task queues)\n",
    "\n",
    "- **Shared memory parallelism:** Parallel threads need to communicate and do so via the same memory (variables, state, etc). (OpenMP)\n",
    "\n",
    "- **Message passing:** Different processes manage their own memory segments. They share data by communicating (passing messages) as needed. (Message Passing Interface (MPI)).\n",
    "\n",
    "\n",
    "### Modern Approach To Speed up code\n",
    "\n",
    "Traditional implemententations of making code parallel are done on a low level. \n",
    "\n",
    "However, open source software has ***evolved*** dramatically over the last few years allowing more ***high level implementations and concise 'pythonic' syntax*** that wraps around low level tools. These modern tools also address the nature of why code takes long to run in the Big Data / Data Science world we live in. That is common reasons why code is slow have changed from function-bound bottlenecks to data-bound bottlenecks. \n",
    "\n",
    "***The focus on this course is to use these modern high level implementations to address both Data and Function Bound bottlecknecks.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some terminology - Processes, threads and shared memory\n",
    "A ***process*** is a collection of resources including program files and memory, that operates as an independent entity. Since each process has a seperate memory space, it can operate independently from other processes. It cannot easily access shared data in other processes.\n",
    "\n",
    "A ***thread*** is the unit of execution within a process. A process can have anywhere from just one thread to many threads. Threads are considered lightweight because they use far less resources than processes. Threads also share the same memory space so are not independent.\n",
    "\n",
    "<figure>\n",
    "  <img src=\"../fig/process_v_thread.png\" style=\"margin:6px;width:300px\"/>\n",
    "</figure><br>\n",
    "\n",
    "<figure>\n",
    "  <img src=\"../fig/process_threads_comparison.png\" style=\"margin:6px;width:400px\"/>\n",
    "</figure><br>\n",
    "\n",
    "The designers of the Python language made the choice that only one thread in a process can run actual Python code by using the so-called global interpreter lock (GIL).\n",
    "\n",
    "External libraries (NumPy, SciPy, Pandas, etc), written in C or other languages, can release the lock and run multi-threaded. Code writen in native python has the GIL limitation.\n",
    "\n",
    "The ***multiprocessing library*** can be used to release the GIL on python native code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.distributed as dd\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import random\n",
    "from multiprocessing import Pool ### The default pool makes one process per CPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speed up a function that could take a while to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#reference:\n",
    "#https://aaltoscicomp.github.io/python-for-scicomp/parallel/\n",
    "\n",
    "def sample(n):\n",
    "    n_inside_circle = 0\n",
    "    for i in range(n):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        if x**2 + y**2 < 1.0:\n",
    "            n_inside_circle += 1\n",
    "    return n_inside_circle / n * 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3.143000\n",
       "1    3.141715\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using apply from pandas\n",
    "ps = pd.Series([10**5,20**5])\n",
    "ps.apply(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pool object from with a with statement \n",
    "with Pool() as p:\n",
    "    result = p.map(sample,ps)\n",
    "    # will engage p.close() automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiprocessing introduces an initial fixed cost in time (creating Pool objects). Knowing what hardware you are working on is needed to tailor the number of processes created with what is available. There is a risk of creating too many processes which make the initial fixed cost excessively large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will come back to the below alternative (Dask) Afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dask equivalent input\n",
    "ds = dd.from_pandas(ps,npartitions = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605 ms ± 10.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit #605 ms ± 10.9 ms per loop\n",
    "result = ds.apply(sample,meta=('x', 'float64')).mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit # 1.08 s ± 47.8 ms per loop\n",
    "p = Pool()\n",
    "result = p.map(sample,ps)\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Compare Multiprocessing to Dask\n",
    "\n",
    "\n",
    "Dask uses multiprocessing by default to overcome the GIL. Hence comparing the run time of the multiprocessing library to Dask with a function-bound problem will yield similar results.\n",
    "\n",
    "\n",
    "Yet dask offers an ecosystem of resource management (Scheduler, diagnostics, data partitions and Task Graphs) that make it a more attractive way to achieve the same thing in most cases. Resource management is handles automatically by the sceduler.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141130625"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for reference, delaying the same function.\n",
    "@dask.delayed\n",
    "def dd_sample(n):\n",
    "    n_inside_circle = 0\n",
    "    for i in range(n):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        if x**2 + y**2 < 1.0:\n",
    "            n_inside_circle += 1\n",
    "    return n_inside_circle / n * 4\n",
    "\n",
    "\n",
    "result = ds.apply(dd_sample,meta=('x', 'float64')).mean().compute()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595 ms ± 1.54 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit #595 ms ± 1.54 ms per loop\n",
    "result = ds.apply(dd_sample,meta=('x', 'float64')).mean().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"keypoints\">\n",
    "\n",
    "### Key points\n",
    "\n",
    "- Using Multiprocessing (or mpi4py - not covered here) are the traditional ways to make functions run in parallel in python\n",
    "- Using Dask and its ecosystem is the modern approach\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "c5664838a1d9cc8c44e1e40f6b8bf12fcc6746780690c0821c07217a3c037223"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
